# Problem parameters:
training:
    #seed_numpy: 4354
    #seed_torch: 2452
    problem:
        name: &name MNIST
        batch_size: &b 64
        mnist_folder: &folder '~/data/mnist'
        use_train_data: True
        resize: [32, 32]
    sampler:
        name: SubsetRandomSampler
        indices: [0, 55000]
        #indices: ~/data/mnist/split_a.txt 
    # optimizer parameters:
    optimizer:
        name: Adam
        lr: 0.01
    # settings parameters
    terminal_conditions:
        loss_stop: 1.0e-5
        episode_limit: 1000
        epoch_limit: 1

# Problem parameters:
validation:
    problem:
        name: *name
        batch_size: 5000
        mnist_folder: *folder
        use_train_data: True  # True because we are splitting the training set to: validation and training
        resize: [32, 32]
    sampler:
        name: SubsetRandomSampler
        indices: [55000, 60000]
        #indices: ~/data/mnist/split_b.txt 
    #dataloader:
    #    drop_last: True

# Problem parameters:
testing:
    #seed_numpy: 4354
    #seed_torch: 2452
    problem:
        name: *name
        batch_size: 10000
        mnist_folder: *folder
        use_train_data: False
        resize: [32, 32]


# Model parameters:
model:
    name: SimpleConvNet
    conv1:
        out_channels: 6
        kernel_size: 5
        stride: 1
        padding: 0
    conv2:
        out_channels: 16
        kernel_size: 5
        stride: 1
        padding: 0
    maxpool1:
        kernel_size: 2
    maxpool2:
        kernel_size: 2
