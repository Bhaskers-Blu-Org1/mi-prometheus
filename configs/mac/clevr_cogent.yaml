training:
    # Problem parameters:
    problem:
        name: &name CLEVR
        batch_size: &b 64
        settings:
            data_folder: &dir '/home/vmarois/CLEVR_CoGenT_v1.0' # magellan server
            set: 'trainA'
            dataset_variant: &var 'CLEVR-CoGenT'
        images:
            raw_images: False
            feature_extractor:
                cnn_model: &cnn 'resnet101'
                num_blocks: 4
        questions:
            embedding_type: &emb 'random'
            embedding_dim: 300

    # Set optimizer.
    optimizer:
        name: Adam
        lr: 1.0e-4
    # Optional parameter, its presence results in clipping gradient to a range (-gradient_clipping, gradient_clipping)
    gradient_clipping: 10
    # Terminal condition parameters:
    terminal_conditions:
        loss_stop: 0.03
        epoch_limit: 20

    # fix the seeds
    seed_torch: 0
    seed_numpy: 0

validation:
    partial_validation_interval: 200
    # Problem parameters:
    problem:
        name: *name
        batch_size: *b
        settings:
            data_folder: *dir
            set: 'valA'
            dataset_variant: *var
        images:
            raw_images: False
            feature_extractor:
                cnn_model: *cnn
                num_blocks: 4
        questions:
            embedding_type: *emb
            embedding_dim: 300

testing:
    # Problem parameters:
    problem:
        name: *name
        batch_size: *b
        settings:
            data_folder: *dir
            set: 'valA'
            dataset_variant: *var
        images:
            raw_images: False
            feature_extractor:
                cnn_model: *cnn
                num_blocks: 4
        questions:
            embedding_type: *emb
            embedding_dim: 300
        max_test_episodes: 3

    multi_tests: {set: ['valA', 'valB'], batch_size: [64, 128]}


# Model parameters:
model:
    name: MACNetwork
    dim: 512
    embed_hidden: 300
    max_step: 12
    self_attention: False
    memory_gate: False
    nb_classes: 28
    dropout: 0.15
