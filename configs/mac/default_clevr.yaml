training:
    # Problem parameters:
    problem:
        name: &name CLEVR
        batch_size: &b 64
        settings:
            data_folder: &dir '~/data/CLEVR_v1.0'
            set: 'train'
            dataset_variant: &var 'CLEVR'
        images:
            raw_images: False
            feature_extractor:
                cnn_model: &cnn 'resnet101'
                num_blocks: 4
        questions:
            embedding_type: &emb 'random'
            embedding_dim: 300
            tasks: ['Exist', 'Count', 'CompareInteger', 'CompareAttribute', 'QueryAttribute']

    # Set optimizer.
    optimizer:
        name: Adam
        lr: 1.0e-4
    # Optional parameter, its presence results in clipping gradient to a range (-gradient_clipping, gradient_clipping)
    gradient_clipping: 10
    # Terminal condition parameters:
    terminal_conditions:
        loss_stop: 0.03
        epoch_limit: 20

    # fix the seeds
    seed_torch: 0
    seed_numpy: 0

validation:
    partial_validation_interval: 200
    # Problem parameters:
    problem:
        name: *name
        batch_size: *b
        settings:
            data_folder: *dir
            set: 'val'
            dataset_variant: *var
        images:
            raw_images: False
            feature_extractor:
                cnn_model: *cnn
                num_blocks: 4
        questions:
            embedding_type: *emb
            embedding_dim: 300
            tasks: ['Exist', 'Count', 'CompareInteger', 'CompareAttribute', 'QueryAttribute']

testing:
    # Problem parameters:
    problem:
        name: *name
        batch_size: *b
        settings:
            data_folder: *dir
            set: 'val'
            dataset_variant: *var
        images:
            raw_images: False
            feature_extractor:
                cnn_model: *cnn
                num_blocks: 4
        questions:
            embedding_type: *emb
            embedding_dim: 300
            tasks: ['Exist', 'Count', 'CompareInteger', 'CompareAttribute', 'QueryAttribute']
        max_test_episodes: -1  # do an entire epoch.
